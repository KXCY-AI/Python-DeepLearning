{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 实验：损失函数"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 实验概要\n",
    "\n",
    "#### 训练数据 (集) 和测试数据 (集)\n",
    "\n",
    "机器学习中，一般将数据分为 **训练数据** 和 **测试数据** 两部分来进行学习和测试等。首先，使用训练数据进行学习，寻找最优的参数；然后，使用测试数据评价训练得到的模型的实际能力。为什么需要将数据分为训练数据和测试数据呢？因为我们追求的是模型的泛化能力。为了正确评价模型的 **泛化能力**，就必须划分训练数据和测试数据。另外，训练数据也可以称为 **监督数据**。\n",
    "\n",
    "![](./img/Sets-1_07.png)\n",
    "\n",
    "某些情况下，在将模型通过测试数据进行评前，可以使用 **验证数据**（Validation Dataset）来看看模型在新数据（验证集和测试集是不同的数据）上的表现如何。同时通过调整超参数，让模型处于最好的状态。另外，验证集不像训练集和测试集，它是非必需的。如果不需要调整超参数，就可以不使用验证集，直接用测试集来评估效果。验证集评估出来的效果并非模型的最终效果，主要是用来调整超参数的，模型最终效果以测试集的评估结果为准。\n",
    "\n",
    "**泛化能力** 是指处理未被观察过的数据（不包含在训练数据中的数据）的能力。获得泛化能力是机器学习的最终目标。比如，在识别手写数字的问题中，泛化能力可能会被用在自动读取明信片的邮政编码的系统上。此时，手写数字识别就必须具备较高的识别“某个人”写的字的能力。注意这里不是“特定的某个人写的特定的文字”，而是“任意一个人写的任意文字”。如果系统只能正确识别已有的训练数据，那有可能是只学习到了训练数据中的个人的习惯写法。\n",
    "\n",
    "因此，仅仅用一个数据集去学习和评价参数，是无法进行正确评价的。这样会导致可以顺利地处理某个数据集，但无法处理其他数据集的情况。顺便说一下，只对某个数据集过度拟合的状态称为 **过拟合**（over ftting）。避免过拟合也是机器学习的一个重要课题。\n",
    "\n",
    "#### 损失函数\n",
    "\n",
    "机器学习中的监督学习本质上是给定一系列训练样本 $(x_i,y_i)$，尝试学习 $x \\rightarrow y$ 的映射关系，使得给定一个 $x$，即便这个 $x$ 不在训练样本中，也能够输出 $\\hat y$，尽量与真实的 $y$ 接近。损失函数是用来估量模型的输出 $\\hat y$ 与真实值 $y$ 之间的差距，给模型的优化指引方向。\n",
    "\n",
    "<img src=\"./img/LossSideBySide_07.png\" width=\"60%\">\n",
    "\n",
    "- 蓝线表示预测。\n",
    "- 红色箭头表示损失\n",
    "\n",
    "从上图可以看到，左侧模型的损失较大；右侧模型的损失较小。因为，左侧曲线图中的红色箭头比右侧曲线图中的对应红色箭头长得多。显然，相较于左侧曲线图中的蓝线，右侧曲线图中的蓝线代表的是预测效果更好的模型。因此，我们创建了一个数学函数，以有意义的方式汇总各个损失，这就是 **损失函数**。如下图，模型通过不断调整与数据点之间的拟合度，从而获得最小的损失值。\n",
    "\n",
    "![](./img/1_KQVi812_aERFRolz_5G3rA_07.gif)\n",
    "\n",
    "模型的结构风险包括了经验风险和结构风险 —— 在监督式学习中，机器学习算法通过以下方式构建模型：检查多个样本并尝试找出可最大限度地减少损失的模型；这一过程称为 **经验风险最小化**。**损失函数** 是经验风险函数的核心部分：\n",
    "\n",
    "$$\\hat\\theta = argmin_{\\theta}\\frac{1}{N}\\sum_{i=1}^{N}L(y_i, f(x_i; \\theta)+\\lambda \\Phi(\\theta))$$\n",
    "\n",
    "式中，前面的均值函数为经验风险，$L(y_i, f(x_i; \\theta)$ 为损失函数，后面的项为结构风险，$\\Phi(\\theta)$ 衡量模型的复杂度。\n",
    "\n",
    "从学习任务的类型出发，可以从广义上将损失函数分为两大类 —— 分类任务损失和回归问题。\n",
    "\n",
    "- **分类任务** 我们要从类别值有限的数据集中预测输出，比如：给定一个手写数字图像的大数据集，将其分为 0～9 中的一个；区分『猫』和『狗』图片。\n",
    "- **回归问题** 处理的则是连续值的预测问题，例如：给定房屋面积、房间数量以及房间大小，预测房屋价格。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 实验目标\n",
    "\n",
    "在本实验中，我们将分别从分类任务与回归问题出发，通过 Python 实现在分类与回归机器学习中的常用损失函数，包括：\n",
    "\n",
    "回归任务损失函数：\n",
    "\n",
    "- 均方误差\n",
    "- 平均绝对误差\n",
    "- 平方偏方误差\n",
    "\n",
    "分类任务损失函数：\n",
    "\n",
    "- Hinge loss\n",
    "- 交叉熵损失\n",
    "\n",
    "从而，使你初步了解如何对模型的经验风险作出可计量的评估。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. 回归损失函数\n",
    "\n",
    "这里主要介绍：\n",
    "\n",
    "- **均方误差**\n",
    "- **平均绝对误差**\n",
    "- **平方偏方误差**\n",
    "\n",
    "三个损失函数"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 均方误差 (平方损失 / L2 损失)\n",
    "\n",
    "均方误差 (**MSE**) 指的是每个样本的平均平方损失。要计算 **MSE**，请求出各个样本的所有平方损失之和，然后除以样本数量：\n",
    "\n",
    "$$\n",
    "\\mathrm{MSE}=\\frac{1}{N} \\sum_{i=1}^{N}\\left(y_{i}-\\hat{y}_{i}\\right)^{2}\n",
    "$$\n",
    "\n",
    "其中：\n",
    "\n",
    "- **`N`：** 训练样本数\n",
    "- **`i`：** 数据集中的训练样本索引号\n",
    "- ${y}_{i}$：** 第 **i** 个训练样本的真实标签\n",
    "- $\\hat{y}_{i}$： 第 **i** 个训练示例的预测\n",
    "\n",
    "虽然 **MSE** 常用于机器学习，但它既不是唯一实用的损失函数，也不是适用于所有情形的最佳损失函数。均方误差（**MSE**）度量的是预测值和实际观测值间差的平方的均值。它只考虑误差的平均大小，不考虑其方向（**正负无关**，由于经过平方，因此公式中的 ${y}_{i}$ 与 $\\hat{y}_{i}$ 的顺序可以互换）。同样，由于经过平方，与真实值偏离较多的预测值会比偏离较少的预测值受到更为严重的惩罚。再加上 **MSE** 的数学特性很好，这使得计算梯度变得更容易。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "作为第一个损失函数，我们稍微拆解一下演算步骤，**MSE** 公式可表达为 —— **MSE** 不考虑方向，预测值与真实值相减顺序可互换：\n",
    "\n",
    "<img src=\"./img/MSE_07.png\" width=\"60%\">\n",
    "\n",
    "使用 Numpy 拆解实现为，**注意运算符号与 Numpy 函数的颜色对应**：\n",
    "\n",
    "<img src=\"./img/numpy-mean-square-error-formula_07.png\" width=\"70%\">\n",
    "\n",
    "假设当前预测值和标签值都是 **3** 个，即：\n",
    "\n",
    "<img src=\"./img/numpy-mse-1_07.png\" width=\"60%\">\n",
    "\n",
    "预测值和标签值都包含三个值。 这意味着 n 的值为 3。进行减法后，最终得到的值如下所示：\n",
    "\n",
    "<img src=\"./img/numpy-mse-2_07.png\" width=\"60%\">\n",
    "\n",
    "然后我们可以对向量中的值求平方：\n",
    "\n",
    "<img src=\"./img/numpy-mse-3_07.png\" width=\"60%\">\n",
    "\n",
    "现在，我们对这些值求和：\n",
    "\n",
    "<img src=\"./img/numpy-mse-4_07.png\" width=\"25%\">\n",
    "\n",
    "运算结果就是我们的 **MSE** 值。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### RMSE\n",
    "\n",
    "**MSE** 执行了平方运算，其运算结果为原始数据集单位 (**量纲**) 的平方。为了与原始数据集单位 (**量纲**) 保持一致，通常我们使用 **RMSE** ，也就是对 **MSE** 的误差运算结果进行开方。**RMSE** (Root Mean Squared Error)，均方误差的平方根，即在 **MSE** 的基础上，取平方根。\n",
    "\n",
    "$$\n",
    "\\mathrm{RMSE}=\\sqrt{\\frac{1}{N} \\sum_{i=1}^{N}\\left(y_{i}-\\hat{y}_{i}\\right)^{2}}\n",
    "$$\n",
    "\n",
    "代码实现如下，我们使用 **`np.square()`** 函数计算真实值与预测值之间的误差值平方；之后，由于我们不想指定 n 的值，使用 **`mean()`** 方法，求出均方误差 **MSE**。这样做的好处是 numpy 不在乎预测和标签（真实值）是否包含一个或一千个值，只要它们的数量终是相同的并一一对应。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "预测值: ['0.00000000', '0.16600000', '0.33300000']\n",
      "真实值：['0.00000000', '0.25400000', '0.99800000']\n",
      "RMSE 为: 0.3872849941150143\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "# 设置预测值\n",
    "y_hat = np.array([0.000, 0.166, 0.333])  \n",
    "# 设置真实值\n",
    "y_true = np.array([0.000, 0.254, 0.998]) \n",
    "\n",
    "# 设置rmse函数\n",
    "def rmse(predictions, targets):\n",
    "    # 求预测值-真实值的差\n",
    "    differences = predictions - targets                      \n",
    "    # 求（预测值-真实值）平方\n",
    "    differences_squared = np.square(differences)             \n",
    "    # 求出均方误差，即mse\n",
    "    mean_of_differences_squared = differences_squared.mean() \n",
    "    # 取平方根得出rmse\n",
    "    rmse_val = np.sqrt(mean_of_differences_squared) \n",
    "    # 返回值\n",
    "    return rmse_val \n",
    "\n",
    "print(\"预测值: \" + str([\"%.8f\" % elem for elem in y_hat]))\n",
    "print(\"真实值：\" + str([\"%.8f\" % elem for elem in y_true]))\n",
    "\n",
    "rmse_val = rmse(y_hat, y_true)\n",
    "print(\"RMSE 为: \" + str(rmse_val))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 平均绝对误差 (L1 损失)\n",
    "\n",
    "数学公式：\n",
    "\n",
    "$$\n",
    "\\mathrm{MAE}=\\frac{1}{N} \\sum_{i=1}^{N}\\left|y_{i}-\\hat{y}_{i}\\right|\n",
    "$$\n",
    "\n",
    "平均绝对误差（**MAE**）度量的是预测值和实际观测值之间绝对差之和的平均值。和 **MSE** 一样，这种度量方法也是在不考虑方向的情况下衡量误差大小。但和 **MSE** 的不同之处在于，**MAE** 需要像线性规划这样更复杂的工具来计算梯度。此外，**MAE** 对异常值更加稳健，因为它不使用平方。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "预测值: ['0.00000000', '0.16600000', '0.33300000']\n",
      "真实值：['0.00000000', '0.25400000', '0.99800000']\n",
      "MAE 为: 0.251\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "# 设置预测值\n",
    "y_hat = np.array([0.000, 0.166, 0.333])  \n",
    "# 设置真实值\n",
    "y_true = np.array([0.000, 0.254, 0.998]) \n",
    "\n",
    "print(\"预测值: \" + str([\"%.8f\" % elem for elem in y_hat]))\n",
    "print(\"真实值：\" + str([\"%.8f\" % elem for elem in y_true]))\n",
    "\n",
    "# 设置mae函数\n",
    "def mae(predictions, targets):\n",
    "    # 求预测值-真实值的差  \n",
    "    differences = predictions - targets                      \n",
    "    # 求（预测值-真实值）绝对值\n",
    "    absolute_differences = np.absolute(differences)          \n",
    "    # 求均值得出 MAE\n",
    "    mean_absolute_differences = absolute_differences.mean()  \n",
    "    # 返回值\n",
    "    return mean_absolute_differences \n",
    "\n",
    "mae_val = mae(y_hat, y_true)\n",
    "print (\"MAE 为: \" + str(mae_val))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 平均偏差误差\n",
    "\n",
    "平均偏差误差（**Mean Bias Error**）与其它损失函数相比，这个函数在机器学习领域没有那么常见。它与 **MAE** 相似，唯一的区别是这个函数没有用绝对值。用这个函数需要注意的一点是，正负误差可以互相抵消。尽管在实际应用中没那么准确，但它可以确定模型存在 **正偏差** 还是 **负偏差**。\n",
    "\n",
    "$$MBE = \\frac{\\sum_{i=1}^{n}(y_i-\\hat{y_i})}{n}$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "预测值: ['0.00000000', '0.16600000', '0.33300000']\n",
      "真实值：['0.00000000', '0.25400000', '0.99800000']\n",
      "MBE 为: -0.251\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "# 设置预测值\n",
    "y_hat = np.array([0.000, 0.166, 0.333])  \n",
    "# 设置真实值\n",
    "y_true = np.array([0.000, 0.254, 0.998]) \n",
    "\n",
    "print(\"预测值: \" + str([\"%.8f\" % elem for elem in y_hat]))\n",
    "print(\"真实值：\" + str([\"%.8f\" % elem for elem in y_true]))\n",
    "\n",
    "# 设置mbe函数\n",
    "def mbe(predictions, targets):\n",
    "    # 求预测值-真实值的差  \n",
    "    differences = predictions - targets   \n",
    "    # 求均值得出 MBE\n",
    "    Mean_Bias_Error = differences.mean()  \n",
    "    # 返回值\n",
    "    return Mean_Bias_Error \n",
    "\n",
    "mbe_val = mbe(y_hat, y_true)\n",
    "print (\"MBE 为: \" + str(mbe_val))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. 分类损失函数\n",
    "\n",
    "本部分主要介绍：\n",
    "\n",
    "- **Hinge loss / 多分类 SVM 损失**\n",
    "- **交叉熵损失 / 负对数似然**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Hinge Loss / 多分类 SVM 损失\n",
    "\n",
    "简言之，在一定的安全间隔内（通常是 **1**），正确类别的分数应高于所有错误类别的分数之和。因此 **hinge loss** 常用于最大间隔分类（**maximum-margin classification**），最常用的是支持向量机。尽管不可微，但它是一个凸函数，因此可以轻而易举地使用机器学习领域中常用的凸优化器。\n",
    "\n",
    "$$SVMLoss = \\sum_{j \\neq y_i}max(0, s_j-s_{y_{i}}+1)$$\n",
    "\n",
    "思考下例，我们有三个训练样本，要预测三个类别（狗、猫和马）。以下是我们通过算法预测出来的每一类的值：\n",
    "\n",
    "<img src=\"./img/1_07.png\" width=\"50%\">\n",
    "\n",
    "运算过程如下：\n",
    "\n",
    "##### image #1\n",
    "\n",
    "- max(0, (1.49) - (-0.39) + 1) + max(0, (4.21) - (-0.39) + 1)\n",
    "- max(0, 2.88) + max(0, 5.6)\n",
    "- 2.88 + 5.6\n",
    "- 8.48 (错误预测，高损失)\n",
    "\n",
    "##### image #2\n",
    "\n",
    "- max(0, (-4.61) - (3.28)+ 1) + max(0, (1.46) - (3.28)+ 1)\n",
    "- max(0, -6.89) + max(0, -0.82)\n",
    "- 0 + 0\n",
    "- 0 (正确预测，零损失)\n",
    "\n",
    "##### image #3\n",
    "\n",
    "- max(0, (1.03) - (-2.27)+ 1) + max(0, (-2.37) - (-2.27)+ 1)\n",
    "- max(0, 4.3) + max(0, 0.9)\n",
    "- 4.3 + 0.9\n",
    "- 5.2 (错误预测，高损失)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "数据点: \n",
      " [[2 2]\n",
      " [3 3]\n",
      " [7 0]\n",
      " [14 47]]\n",
      "\n",
      "\n",
      "对应标签: \n",
      " [[1]\n",
      " [-1]\n",
      " [1]\n",
      " [-1]]\n",
      "\n",
      "\n",
      " 给定数据的 Hinge Loss： [0.986]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/numpy/core/fromnumeric.py:87: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
      "  return ufunc.reduce(obj, axis, dtype, out, **passkwargs)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "# 对于二分类来说，hinge loss的函数表达式为max(0,1-y*y')\n",
    "# y为预测值，y'为实际值\n",
    "def hinge_loss_single(feature_vector, label, theta, theta_0):\n",
    "    \n",
    "    # 计算预测值\n",
    "    ydash = label*(np.matmul(theta, feature_vector) + theta_0)\n",
    "    \n",
    "    # 根据公式定义损失\n",
    "    hinge = np.max([0.0, 1 - ydash*label])\n",
    "    return hinge\n",
    "\n",
    "# 计算整体的hinge loss损失值\n",
    "def hinge_loss_full(feature_matrix, labels, theta, theta_0):\n",
    "    \n",
    "    # 损失初始值\n",
    "    tothinge = 0\n",
    "    \n",
    "    # 样本的数量\n",
    "    num = len(feature_matrix)\n",
    "    \n",
    "    # 分别计算每个样本的损失值，并将其相加得到总的损失值\n",
    "    for i in range(num):\n",
    "        tothinge = tothinge + hinge_loss_single(feature_matrix[i], \n",
    "                                                labels[i], \n",
    "                                                theta, \n",
    "                                                theta_0)        \n",
    "    hinge = tothinge   \n",
    "    return hinge\n",
    "\n",
    "feature_matrix = np.array([[2,2], [3,3], [7,0], [14,47]], dtype=object)\n",
    "theta = np.array([0.002,0.6])\n",
    "theta_0 = 0\n",
    "labels = np.array([[1], [-1], [1], [-1]], dtype=object)\n",
    "hingell = hinge_loss_full(feature_matrix, labels, theta, theta_0)\n",
    "\n",
    "print('数据点: \\n', feature_matrix)\n",
    "print('\\n\\n对应标签: \\n', labels)\n",
    "print('\\n\\n 给定数据的 Hinge Loss：', hingell)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 交叉熵损失 / 负对数似然\n",
    "\n",
    "交叉熵误差（**Cross Entropy Error**）是分类问题中最常见的设置。随着预测概率偏离实际标签，交叉熵损失会逐渐增加。\n",
    "\n",
    "首先，写出单个样本的交叉熵损失函数：\n",
    "\n",
    "$$\n",
    "\\text { CrossEntropy Loss }=-\\left(y_{i} \\log \\left(\\hat{y}_{i}\\right)+\\left(1-y_{i}\\right) \\log \\left(1-\\hat{y}_{i}\\right)\\right)\n",
    "$$\n",
    "\n",
    "- 当实际标签为 **1 (y<sub>i</sub>=1)** 时，函数的后半部分消失，即：$\\text { CrossEntropy Loss }=-\\log \\left(\\hat{y}_{i}\\right)$\n",
    "- 当实际标签为 **0 (y<sub>i</sub>=0)** 时，函数的前半部分消失，即：$\\text { CrossEntropy Loss }=-\\log \\left(1-\\hat{y}_{i}\\right)$\n",
    "\n",
    "下面用 Python 代码实现以上公式："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x432 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "# 使用sigmoid函数进行分类\n",
    "def sigmoid(z):\n",
    "    return 1.0 / (1.0 + np.exp(-z))\n",
    "\n",
    "# 定义交叉熵损失函数\n",
    "def cross_entropy_loss(yHat, yi):\n",
    "    if yi == 1:\n",
    "        return -np.log(yHat)\n",
    "    \n",
    "    else:\n",
    "        return -np.log(1 - yHat)\n",
    "\n",
    "# 计算Z的样本值\n",
    "z = np.arange(-10, 10, 0.1)\n",
    "\n",
    "# 计算sigmoid概率值\n",
    "h_z = sigmoid(z)\n",
    "\n",
    "# 计算实际值y = 1时损失函数的值\n",
    "# -log(h(x))\n",
    "cost_1 = cross_entropy_loss(h_z, 1)\n",
    "\n",
    "# 计算实际值y = 0时损失函数的值\n",
    "# -log(1 - h(x))\n",
    "cost_0 = cross_entropy_loss(h_z, 0)\n",
    "\n",
    "# 绘制交叉熵损失函数图\n",
    "fig, ax = plt.subplots(figsize=(6,6))\n",
    "# 绘制实际标签为 1的交叉熵损失函数曲线\n",
    "plt.plot(h_z, cost_1, label='CrossEntropy Loss if yi=1') \n",
    "# 绘制实际标签为 0的交叉熵损失函数曲线\n",
    "plt.plot(h_z, cost_0, label='CrossEntropy Loss if yi=0') \n",
    "# Sigmoid作为激活函数时的输出概率\n",
    "plt.xlabel('Sigmoid Output Probability')                 \n",
    "plt.ylabel('CrossEntropy Loss')\n",
    "plt.legend(loc='best')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "看了 CrossEntropy Loss 的图形，简单明了。\n",
    "\n",
    "- 先看蓝色，**Y<sub>i</sub> = 1**, 横坐标是预测输出，纵坐标是交叉熵损失函数 CrossEntropy Loss。显然，预测输出越接近真实样本标签 1，损失函数 CrossEntropy Loss 越小；预测输出越接近 0，CrossEntropy Loss 越大。因此，函数的变化趋势完全符合实际需要的情况。\n",
    "- 在看橙色，**Y<sub>i</sub> = 0**, 同样，预测输出越接近真实样本标签 0，损失函数 CrossEntropy Loss 越小；预测函数越接近 1，CrossEntropy Loss 越大。函数的变化趋势也完全符合实际需要的情况。\n",
    "\n",
    "从上图中，可以帮助我们对交叉熵损失函数有更直观的理解。无论真实样本标签 **Y<sub>i</sub>** 是 0 还是 1，CrossEntropy Loss 都表征了预测输出与 **Y<sub>i</sub>** 的差距。另外，重点提一点的是，从图形中我们可以发现：预测输出与 **Y<sub>i</sub>** 差得越多，L 的值越大，也就是说对当前模型的 **惩罚** 越大，而且是非线性增大，是一种类似指数增长的级别。这是由 **log** 函数本身的特性所决定的。这样的好处是模型会倾向于让预测输出更接近真实样本标签 **Y<sub>i</sub>**。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "我们已经推导出了单个样本的损失函数，是如果是计算 N 个样本的总的损失函数，只要将 N 个 损失值叠加起来求平均就可以了。\n",
    "\n",
    "$$\n",
    "\\text { Log loss }=\\frac{1}{N} \\sum_{i=1}^{N}-\\left(y_{i} * \\log \\left(p_{i}\\right)+\\left(1-y_{i}\\right) * \\log \\left(1-p_{i}\\right)\\right)\n",
    "$$\n",
    "\n",
    "另外，我们通常只考虑 **y<sub>i</sub>=1** 的情况，简言之，我们只是把真实值与预测概率的对数相乘。实现代码如下："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "交叉熵损失为: 0.7135329699138555\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "# 设置预测值概率\n",
    "predictions = np.array([[0.25,0.25,0.25,0.25],\n",
    "                        [0.01,0.01,0.01,0.96]])\n",
    "# 设置标签值/真实值\n",
    "targets = np.array([[0,0,0,1],\n",
    "                   [0,0,0,1]])\n",
    "\n",
    "# 定义交叉熵函数\n",
    "\"\"\"\n",
    "加上了一个微小值 epsilon。\n",
    "这是因为，当出现 np.log(0)时， np.log(0)会变为负无限大的 -inf，\n",
    "这样一来就会导致后续计算无法进行。\n",
    "作为保护性对策，添加一个微小值可以防止负无限大的发生。\n",
    "\"\"\"\n",
    "# 添加微小值\n",
    "def cross_entropy(predictions, targets, epsilon=1e-10): \n",
    "    \n",
    "    # 指定输入 predictions 数组范围，应该在微小值和（1-微小值）之间，避免Log(0)出现\n",
    "    predictions = np.clip(predictions, epsilon, 1 - epsilon) \n",
    "    \n",
    "    # predictions 形状为（2,4），当前有两个样本，即 N = 2\n",
    "    N = predictions.shape[0]   \n",
    "    \n",
    "    # 实现交叉熵损失公式\n",
    "    ce_loss = -np.sum(np.sum(targets * np.log(predictions + 1e-5)))/N \n",
    "    return ce_loss\n",
    "\n",
    "cross_entropy_loss = cross_entropy(predictions, targets)\n",
    "print (\"交叉熵损失为: \" + str(cross_entropy_loss))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 实验小结\n",
    "\n",
    "在本实验中，你通过 Python 实现在分类与回归机器学习中的常用损失函数，包括：均方误差、平均绝对误差、平方偏方误差；以及：Hinge loss Hinge Loss / 交叉熵损失。从而，使你初步了解如何对模型的经验风险作出可计量的评估。"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
